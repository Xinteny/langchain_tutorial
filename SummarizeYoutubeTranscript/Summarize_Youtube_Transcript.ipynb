{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import TextFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_list = YouTubeTranscriptApi.list_transcripts('UF9Iqmg94tk')\n",
    "print(transcript_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trz7g-wilxs = \"5 RULES FOR THE REST OF YOUR LIFE\" | Matthew McConaughey MOTIVATIONAL SPEECH\n",
    "# UF9Iqmg94tk = \"Consistent Hashing | Algorithms You Should Know #1\"\n",
    "transcript = YouTubeTranscriptApi.get_transcript('UF9Iqmg94tk', languages=['en-US'])\n",
    "formatter = TextFormatter()\n",
    "text_formatted = formatter.format_transcript(transcript)\n",
    "with open('transcript.txt', 'w', encoding='utf-8') as text_file:\n",
    "    text_file.write(text_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./transcript.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 6768 characters in your document\n"
     ]
    }
   ],
   "source": [
    "print (f'You have {len(docs)} document(s) in your data')\n",
    "print (f'There are {len(docs[0].page_content)} characters in your document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 7 split document(s)\n"
     ]
    }
   ],
   "source": [
    "print (f'You have {len(split_docs)} split document(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "llm = OpenAI(temperature=0)\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_docs = split_docs[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"What do DynamoDB, Apache Cassandra, Discord, and聽\n",
      "Akamai CDN have in common? They all use consistent聽聽\n",
      "hashing. Now, what is consistent hashing? Why do all聽\n",
      "the cool kids use it? In this video, we'll learn聽聽\n",
      "all about it. Let's dive right in. In a large scale聽\n",
      "distributed system, data does not fit on a single聽聽\n",
      "server. They are distributed across many machines.聽\n",
      "This is called horizontal scaling. To build such聽聽\n",
      "a system with predictable performance. it is聽\n",
      "important to distribute the data evenly across聽聽\n",
      "those servers. A common method to distribute聽\n",
      "data as evenly as possible among servers is聽聽\n",
      "simple hashing. This is how it works. First, for each聽\n",
      "object, we hash its key with a hashing function聽聽\n",
      "like MD5 or MurmurHash. This maps the object聽\n",
      "key to a known range of numerical values.聽聽\n",
      "A good hashing function distributes the聽\n",
      "hashes evenly across the entire range.聽聽\n",
      "Second, we perform the modulo operation on the聽\n",
      "hash against the number of servers. This determines聽聽\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\" This video explains consistent hashing, a method used by DynamoDB, Apache Cassandra, Discord, and Akamai CDN to evenly distribute data across multiple servers. It works by hashing the object key with a hashing function, then performing a modulo operation on the hash against the number of servers. This determines which server the object should be stored on.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Total Tokens: 547\n",
      "Prompt Tokens: 422\n",
      "Completion Tokens: 125\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.01094\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    chain.run(input_documents=input_docs)\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Successful Requests: {cb.successful_requests}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
